[{"model": "ver0.keyword", "pk": 1, "fields": {"name": "language modeling"}}, {"model": "ver0.keyword", "pk": 2, "fields": {"name": "speech"}}, {"model": "ver0.keyword", "pk": 3, "fields": {"name": "audiovisual speech synthesis"}}, {"model": "ver0.keyword", "pk": 4, "fields": {"name": "aam modeling"}}, {"model": "ver0.keyword", "pk": 5, "fields": {"name": "direction of arrival"}}, {"model": "ver0.keyword", "pk": 6, "fields": {"name": "direction arrival"}}, {"model": "ver0.keyword", "pk": 7, "fields": {"name": "voice detection"}}, {"model": "ver0.keyword", "pk": 8, "fields": {"name": "voice activity detection"}}, {"model": "ver0.keyword", "pk": 9, "fields": {"name": "turn taking"}}, {"model": "ver0.keyword", "pk": 10, "fields": {"name": "microphone array"}}, {"model": "ver0.keyword", "pk": 11, "fields": {"name": "DOA"}}, {"model": "ver0.keyword", "pk": 12, "fields": {"name": "turn take"}}, {"model": "ver0.keyword", "pk": 13, "fields": {"name": "VAD"}}, {"model": "ver0.keyword", "pk": 14, "fields": {"name": "conversation detection"}}, {"model": "ver0.keyword", "pk": 15, "fields": {"name": "speech production"}}, {"model": "ver0.keyword", "pk": 16, "fields": {"name": "realtime magnetic resonance imaging"}}, {"model": "ver0.keyword", "pk": 17, "fields": {"name": "voice production"}}, {"model": "ver0.keyword", "pk": 18, "fields": {"name": "articulatory modeling"}}, {"model": "ver0.keyword", "pk": 19, "fields": {"name": "MRI"}}, {"model": "ver0.keyword", "pk": 20, "fields": {"name": "articulatory"}}, {"model": "ver0.keyword", "pk": 21, "fields": {"name": "noise estimation"}}, {"model": "ver0.keyword", "pk": 22, "fields": {"name": "robust speech recognition"}}, {"model": "ver0.keyword", "pk": 23, "fields": {"name": "monte carlo"}}, {"model": "ver0.keyword", "pk": 24, "fields": {"name": "speech recognition"}}, {"model": "ver0.keyword", "pk": 25, "fields": {"name": "speaker turn"}}, {"model": "ver0.keyword", "pk": 26, "fields": {"name": "floor control"}}, {"model": "ver0.keyword", "pk": 27, "fields": {"name": "multiparty conversation"}}, {"model": "ver0.keyword", "pk": 28, "fields": {"name": "multiple frame feature"}}, {"model": "ver0.keyword", "pk": 29, "fields": {"name": "conversation"}}, {"model": "ver0.keyword", "pk": 30, "fields": {"name": "dynamic"}}, {"model": "ver0.keyword", "pk": 31, "fields": {"name": "AMI"}}, {"model": "ver0.keyword", "pk": 32, "fields": {"name": "non-verbal features"}}, {"model": "ver0.keyword", "pk": 33, "fields": {"name": "turn"}}, {"model": "ver0.keyword", "pk": 34, "fields": {"name": "hierarchical control"}}, {"model": "ver0.keyword", "pk": 35, "fields": {"name": "dynamic bayesian network"}}, {"model": "ver0.keyword", "pk": 36, "fields": {"name": "MAP"}}, {"model": "ver0.keyword", "pk": 37, "fields": {"name": "accent adaptation"}}, {"model": "ver0.keyword", "pk": 38, "fields": {"name": "GMM"}}, {"model": "ver0.keyword", "pk": 39, "fields": {"name": "accented speech recognition"}}, {"model": "ver0.keyword", "pk": 40, "fields": {"name": "speaker adaptation"}}, {"model": "ver0.keyword", "pk": 41, "fields": {"name": "SRE"}}, {"model": "ver0.keyword", "pk": 42, "fields": {"name": "IST"}}, {"model": "ver0.keyword", "pk": 43, "fields": {"name": "NIST"}}, {"model": "ver0.keyword", "pk": 44, "fields": {"name": "cluster"}}, {"model": "ver0.keyword", "pk": 45, "fields": {"name": "hmm-based speech synthesis"}}, {"model": "ver0.keyword", "pk": 46, "fields": {"name": "speech sound"}}, {"model": "ver0.keyword", "pk": 47, "fields": {"name": "autoregressive"}}, {"model": "ver0.keyword", "pk": 48, "fields": {"name": "decision tree clustering"}}, {"model": "ver0.keyword", "pk": 49, "fields": {"name": "HMM"}}, {"model": "ver0.keyword", "pk": 50, "fields": {"name": "MDL"}}, {"model": "ver0.keyword", "pk": 51, "fields": {"name": "autoregressive hmm"}}, {"model": "ver0.keyword", "pk": 52, "fields": {"name": "accent identification"}}, {"model": "ver0.keyword", "pk": 53, "fields": {"name": "recognition of accented speech"}}, {"model": "ver0.keyword", "pk": 54, "fields": {"name": "VID"}}, {"model": "ver0.keyword", "pk": 55, "fields": {"name": "TTS"}}, {"model": "ver0.keyword", "pk": 56, "fields": {"name": "spoken documents"}}, {"model": "ver0.keyword", "pk": 57, "fields": {"name": "confidence measure"}}, {"model": "ver0.keyword", "pk": 58, "fields": {"name": "spoken language"}}, {"model": "ver0.keyword", "pk": 59, "fields": {"name": "confidence measures"}}, {"model": "ver0.keyword", "pk": 60, "fields": {"name": "contextual coherence"}}, {"model": "ver0.keyword", "pk": 61, "fields": {"name": "PMI"}}, {"model": "ver0.keyword", "pk": 62, "fields": {"name": "speaker verification"}}, {"model": "ver0.keyword", "pk": 63, "fields": {"name": "factor analysis"}}, {"model": "ver0.keyword", "pk": 64, "fields": {"name": "PCA"}}, {"model": "ver0.keyword", "pk": 65, "fields": {"name": "WCCN"}}, {"model": "ver0.keyword", "pk": 66, "fields": {"name": "i-vector"}}, {"model": "ver0.keyword", "pk": 67, "fields": {"name": "principal component analysis"}}, {"model": "ver0.keyword", "pk": 68, "fields": {"name": "MCRA"}}, {"model": "ver0.keyword", "pk": 69, "fields": {"name": "change point detection"}}, {"model": "ver0.keyword", "pk": 70, "fields": {"name": "noise"}}, {"model": "ver0.keyword", "pk": 71, "fields": {"name": "line asr"}}, {"model": "ver0.keyword", "pk": 72, "fields": {"name": "ASR"}}, {"model": "ver0.keyword", "pk": 73, "fields": {"name": "inference"}}, {"model": "ver0.keyword", "pk": 74, "fields": {"name": "OCP"}}, {"model": "ver0.keyword", "pk": 75, "fields": {"name": "CRA"}}, {"model": "ver0.keyword", "pk": 76, "fields": {"name": "joint noise compensation"}}, {"model": "ver0.keyword", "pk": 77, "fields": {"name": "minimum error"}}, {"model": "ver0.keyword", "pk": 78, "fields": {"name": "bayesian on-line inference"}}, {"model": "ver0.keyword", "pk": 79, "fields": {"name": "JAC"}}, {"model": "ver0.keyword", "pk": 80, "fields": {"name": "minimum search window"}}, {"model": "ver0.keyword", "pk": 81, "fields": {"name": "BOCPD"}}, {"model": "ver0.keyword", "pk": 82, "fields": {"name": "on-line asr"}}, {"model": "ver0.keyword", "pk": 83, "fields": {"name": "non-stationary noise tracking and estimate"}}, {"model": "ver0.keyword", "pk": 84, "fields": {"name": "non-native phone perception"}}, {"model": "ver0.keyword", "pk": 85, "fields": {"name": "PAM"}}, {"model": "ver0.keyword", "pk": 86, "fields": {"name": "foreign language acquisition"}}, {"model": "ver0.keyword", "pk": 87, "fields": {"name": "cross -"}}, {"model": "ver0.keyword", "pk": 88, "fields": {"name": "IEEE 80211"}}, {"model": "ver0.keyword", "pk": 89, "fields": {"name": "SNR"}}, {"model": "ver0.keyword", "pk": 90, "fields": {"name": "differentiated maximum retry limit"}}, {"model": "ver0.keyword", "pk": 91, "fields": {"name": "phone impact"}}, {"model": "ver0.keyword", "pk": 92, "fields": {"name": "WER"}}, {"model": "ver0.keyword", "pk": 93, "fields": {"name": "priority class"}}, {"model": "ver0.keyword", "pk": 94, "fields": {"name": "forensic"}}, {"model": "ver0.keyword", "pk": 95, "fields": {"name": "calibration"}}, {"model": "ver0.keyword", "pk": 96, "fields": {"name": "speaker recognition"}}, {"model": "ver0.keyword", "pk": 97, "fields": {"name": "short utterances"}}, {"model": "ver0.keyword", "pk": 98, "fields": {"name": "short utterance"}}, {"model": "ver0.keyword", "pk": 99, "fields": {"name": "forensics"}}, {"model": "ver0.keyword", "pk": 100, "fields": {"name": "pronunciation training"}}, {"model": "ver0.keyword", "pk": 101, "fields": {"name": "audio feature"}}, {"model": "ver0.keyword", "pk": 102, "fields": {"name": "CAPT"}}, {"model": "ver0.keyword", "pk": 103, "fields": {"name": "pronunciation"}}, {"model": "ver0.keyword", "pk": 104, "fields": {"name": "MLN"}}, {"model": "ver0.keyword", "pk": 105, "fields": {"name": "articulatory feature"}}, {"model": "ver0.keyword", "pk": 106, "fields": {"name": "IPA"}}, {"model": "ver0.keyword", "pk": 107, "fields": {"name": "ipa chart"}}, {"model": "ver0.keyword", "pk": 108, "fields": {"name": "automatic speech recognition"}}, {"model": "ver0.keyword", "pk": 109, "fields": {"name": "vocal tract length normalization"}}, {"model": "ver0.keyword", "pk": 110, "fields": {"name": "VTL"}}, {"model": "ver0.keyword", "pk": 111, "fields": {"name": "VTLN"}}, {"model": "ver0.keyword", "pk": 112, "fields": {"name": "elastic registration"}}, {"model": "ver0.keyword", "pk": 113, "fields": {"name": "spectral subtraction"}}, {"model": "ver0.keyword", "pk": 114, "fields": {"name": "spectral clustering"}}, {"model": "ver0.keyword", "pk": 115, "fields": {"name": "overlap speech detection"}}, {"model": "ver0.keyword", "pk": 116, "fields": {"name": "cosine distance"}}, {"model": "ver0.keyword", "pk": 117, "fields": {"name": "probabilistic model"}}, {"model": "ver0.keyword", "pk": 118, "fields": {"name": "fujisaki model"}}, {"model": "ver0.keyword", "pk": 119, "fields": {"name": "em algorithm"}}, {"model": "ver0.keyword", "pk": 120, "fields": {"name": "hidden markov model"}}, {"model": "ver0.keyword", "pk": 121, "fields": {"name": "statistical model"}}, {"model": "ver0.keyword", "pk": 122, "fields": {"name": "speech f0 contours"}}, {"model": "ver0.keyword", "pk": 123, "fields": {"name": "physical models of the human vocal tract"}}, {"model": "ver0.keyword", "pk": 124, "fields": {"name": "speech science"}}, {"model": "ver0.keyword", "pk": 125, "fields": {"name": "vowel production"}}, {"model": "ver0.keyword", "pk": 126, "fields": {"name": "S3T"}}, {"model": "ver0.keyword", "pk": 127, "fields": {"name": "education in acoustics"}}, {"model": "ver0.keyword", "pk": 128, "fields": {"name": "education acoustic"}}, {"model": "ver0.keyword", "pk": 129, "fields": {"name": "vowel space"}}, {"model": "ver0.keyword", "pk": 130, "fields": {"name": "activation"}}, {"model": "ver0.keyword", "pk": 131, "fields": {"name": "rating"}}, {"model": "ver0.keyword", "pk": 132, "fields": {"name": "arousal rating"}}, {"model": "ver0.keyword", "pk": 133, "fields": {"name": "knowledge-based"}}, {"model": "ver0.keyword", "pk": 134, "fields": {"name": "cross-corpora"}}, {"model": "ver0.keyword", "pk": 135, "fields": {"name": "inter-rater reliability"}}, {"model": "ver0.keyword", "pk": 136, "fields": {"name": "multi - channel"}}, {"model": "ver0.keyword", "pk": 137, "fields": {"name": "unsupervised"}}, {"model": "ver0.keyword", "pk": 138, "fields": {"name": "base"}}, {"model": "ver0.keyword", "pk": 139, "fields": {"name": "reverberant noise robustness"}}, {"model": "ver0.keyword", "pk": 140, "fields": {"name": "AURORA4"}}, {"model": "ver0.keyword", "pk": 141, "fields": {"name": "VTS"}}, {"model": "ver0.keyword", "pk": 142, "fields": {"name": "vector taylor series"}}, {"model": "ver0.keyword", "pk": 143, "fields": {"name": "training"}}, {"model": "ver0.keyword", "pk": 144, "fields": {"name": "adaptive training"}}, {"model": "ver0.keyword", "pk": 145, "fields": {"name": "AURORA"}}, {"model": "ver0.keyword", "pk": 146, "fields": {"name": "segmental intonation"}}, {"model": "ver0.keyword", "pk": 147, "fields": {"name": "F0"}}, {"model": "ver0.keyword", "pk": 148, "fields": {"name": "perception"}}, {"model": "ver0.keyword", "pk": 149, "fields": {"name": "prominence"}}, {"model": "ver0.keyword", "pk": 150, "fields": {"name": "f0"}}, {"model": "ver0.keyword", "pk": 151, "fields": {"name": "intonation"}}, {"model": "ver0.keyword", "pk": 152, "fields": {"name": "ESPF"}}, {"model": "ver0.keyword", "pk": 153, "fields": {"name": "discourse"}}, {"model": "ver0.keyword", "pk": 154, "fields": {"name": "AG500"}}, {"model": "ver0.keyword", "pk": 155, "fields": {"name": "SPF"}}, {"model": "ver0.keyword", "pk": 156, "fields": {"name": "spontaneous speech"}}, {"model": "ver0.keyword", "pk": 157, "fields": {"name": "EMA"}}, {"model": "ver0.keyword", "pk": 158, "fields": {"name": "vocal tract length"}}, {"model": "ver0.keyword", "pk": 159, "fields": {"name": "vocal-tract length"}}, {"model": "ver0.keyword", "pk": 160, "fields": {"name": "liquids"}}, {"model": "ver0.keyword", "pk": 161, "fields": {"name": "consonant"}}, {"model": "ver0.keyword", "pk": 162, "fields": {"name": "syllabic consonants"}}, {"model": "ver0.keyword", "pk": 163, "fields": {"name": "vocalization"}}, {"model": "ver0.keyword", "pk": 164, "fields": {"name": "vowel synthesis"}}, {"model": "ver0.keyword", "pk": 165, "fields": {"name": "historical instruments"}}, {"model": "ver0.keyword", "pk": 166, "fields": {"name": "historical instrument"}}, {"model": "ver0.keyword", "pk": 167, "fields": {"name": "REDIAL"}}, {"model": "ver0.keyword", "pk": 168, "fields": {"name": "ABE"}}, {"model": "ver0.keyword", "pk": 169, "fields": {"name": "DIAL"}}, {"model": "ver0.keyword", "pk": 170, "fields": {"name": "ICE"}}, {"model": "ver0.keyword", "pk": 171, "fields": {"name": "SPL"}}, {"model": "ver0.keyword", "pk": 172, "fields": {"name": "DIA"}}, {"model": "ver0.keyword", "pk": 173, "fields": {"name": "SPLICE"}}, {"model": "ver0.keyword", "pk": 174, "fields": {"name": "l2 german"}}, {"model": "ver0.keyword", "pk": 175, "fields": {"name": "vowel epenthesis"}}, {"model": "ver0.keyword", "pk": 176, "fields": {"name": "l1 chinese"}}, {"model": "ver0.keyword", "pk": 177, "fields": {"name": "ART"}}, {"model": "ver0.keyword", "pk": 178, "fields": {"name": "whole-word modeling"}}, {"model": "ver0.keyword", "pk": 179, "fields": {"name": "point process model"}}, {"model": "ver0.keyword", "pk": 180, "fields": {"name": "keyword spotting"}}, {"model": "ver0.keyword", "pk": 181, "fields": {"name": "spot"}}, {"model": "ver0.keyword", "pk": 182, "fields": {"name": "CART"}}, {"model": "ver0.keyword", "pk": 183, "fields": {"name": "phonetic timing"}}, {"model": "ver0.keyword", "pk": 184, "fields": {"name": "GPU"}}, {"model": "ver0.keyword", "pk": 185, "fields": {"name": "distribute optimization"}}, {"model": "ver0.keyword", "pk": 186, "fields": {"name": "deep neural network"}}, {"model": "ver0.keyword", "pk": 187, "fields": {"name": "distributed optimization"}}, {"model": "ver0.keyword", "pk": 188, "fields": {"name": "MLLR"}}, {"model": "ver0.keyword", "pk": 189, "fields": {"name": "stack"}}, {"model": "ver0.keyword", "pk": 190, "fields": {"name": "LLR"}}, {"model": "ver0.keyword", "pk": 191, "fields": {"name": "semi-supervised training"}}, {"model": "ver0.keyword", "pk": 192, "fields": {"name": "CML"}}, {"model": "ver0.keyword", "pk": 193, "fields": {"name": "neural networks"}}, {"model": "ver0.keyword", "pk": 194, "fields": {"name": "clean condition training"}}, {"model": "ver0.keyword", "pk": 195, "fields": {"name": "CMLLR"}}, {"model": "ver0.keyword", "pk": 196, "fields": {"name": "feature extraction"}}, {"model": "ver0.keyword", "pk": 197, "fields": {"name": "multilingual training"}}, {"model": "ver0.keyword", "pk": 198, "fields": {"name": "neural network"}}, {"model": "ver0.keyword", "pk": 199, "fields": {"name": "feature"}}, {"model": "ver0.keyword", "pk": 200, "fields": {"name": "stacked bottle-neck"}}, {"model": "ver0.keyword", "pk": 201, "fields": {"name": "reverberation"}}, {"model": "ver0.keyword", "pk": 202, "fields": {"name": "multi-condition training"}}, {"model": "ver0.keyword", "pk": 203, "fields": {"name": "dynamic time warping"}}, {"model": "ver0.keyword", "pk": 204, "fields": {"name": "TIMIT"}}, {"model": "ver0.keyword", "pk": 205, "fields": {"name": "ISA"}}, {"model": "ver0.keyword", "pk": 206, "fields": {"name": "time frequency"}}, {"model": "ver0.keyword", "pk": 207, "fields": {"name": "MIT"}}, {"model": "ver0.keyword", "pk": 208, "fields": {"name": "intrinsic spectral analysis"}}, {"model": "ver0.keyword", "pk": 209, "fields": {"name": "STD"}}, {"model": "ver0.keyword", "pk": 210, "fields": {"name": "spoken term detection"}}, {"model": "ver0.keyword", "pk": 211, "fields": {"name": "gaussian posteriorgram"}}, {"model": "ver0.keyword", "pk": 212, "fields": {"name": "tools"}}, {"model": "ver0.keyword", "pk": 213, "fields": {"name": "recording"}}, {"model": "ver0.keyword", "pk": 214, "fields": {"name": "crowdsourcing"}}, {"model": "ver0.keyword", "pk": 215, "fields": {"name": "test"}}, {"model": "ver0.keyword", "pk": 216, "fields": {"name": "crowdsource"}}, {"model": "ver0.keyword", "pk": 217, "fields": {"name": "study"}}, {"model": "ver0.keyword", "pk": 218, "fields": {"name": "tool"}}, {"model": "ver0.keyword", "pk": 219, "fields": {"name": "scalable studies"}}, {"model": "ver0.keyword", "pk": 220, "fields": {"name": "labeling"}}, {"model": "ver0.keyword", "pk": 221, "fields": {"name": "field tests"}}, {"model": "ver0.keyword", "pk": 222, "fields": {"name": "mobile phone app"}}, {"model": "ver0.keyword", "pk": 223, "fields": {"name": "mobile"}}, {"model": "ver0.keyword", "pk": 224, "fields": {"name": "gaussian mixture model"}}, {"model": "ver0.keyword", "pk": 225, "fields": {"name": "telephone speech"}}, {"model": "ver0.keyword", "pk": 226, "fields": {"name": "text speech"}}, {"model": "ver0.keyword", "pk": 227, "fields": {"name": "model"}}, {"model": "ver0.keyword", "pk": 228, "fields": {"name": "enhancement"}}, {"model": "ver0.keyword", "pk": 229, "fields": {"name": "intelligibility enhancement"}}, {"model": "ver0.keyword", "pk": 230, "fields": {"name": "spectral envelope estimation"}}, {"model": "ver0.keyword", "pk": 231, "fields": {"name": "sparse representation"}}, {"model": "ver0.keyword", "pk": 232, "fields": {"name": "redundant dictionaries"}}, {"model": "ver0.keyword", "pk": 233, "fields": {"name": "OMP"}}, {"model": "ver0.keyword", "pk": 234, "fields": {"name": "redundant dictionary"}}, {"model": "ver0.keyword", "pk": 235, "fields": {"name": "eigenvoice"}}, {"model": "ver0.keyword", "pk": 236, "fields": {"name": "on-line adaptation"}}, {"model": "ver0.keyword", "pk": 237, "fields": {"name": "eigenvoices"}}, {"model": "ver0.keyword", "pk": 238, "fields": {"name": "fast adaptation"}}, {"model": "ver0.keyword", "pk": 239, "fields": {"name": "PSTM"}}, {"model": "ver0.keyword", "pk": 240, "fields": {"name": "l2 consonants"}}, {"model": "ver0.keyword", "pk": 241, "fields": {"name": "identification"}}, {"model": "ver0.keyword", "pk": 242, "fields": {"name": "PST"}}, {"model": "ver0.keyword", "pk": 243, "fields": {"name": "VCV"}}, {"model": "ver0.keyword", "pk": 244, "fields": {"name": "l2 acquisition"}}, {"model": "ver0.keyword", "pk": 245, "fields": {"name": "STM"}}, {"model": "ver0.keyword", "pk": 246, "fields": {"name": "ranking perceptron"}}, {"model": "ver0.keyword", "pk": 247, "fields": {"name": "discriminative language modeling"}}, {"model": "ver0.keyword", "pk": 248, "fields": {"name": "unsupervised training"}}, {"model": "ver0.keyword", "pk": 249, "fields": {"name": "DLM"}}, {"model": "ver0.keyword", "pk": 250, "fields": {"name": "rank"}}, {"model": "ver0.keyword", "pk": 251, "fields": {"name": "vowel sentence"}}, {"model": "ver0.keyword", "pk": 252, "fields": {"name": "spectral degradation"}}, {"model": "ver0.keyword", "pk": 253, "fields": {"name": "speech intelligibility"}}, {"model": "ver0.keyword", "pk": 254, "fields": {"name": "prediction"}}, {"model": "ver0.keyword", "pk": 255, "fields": {"name": "STT"}}, {"model": "ver0.keyword", "pk": 256, "fields": {"name": "radial basis functions"}}, {"model": "ver0.keyword", "pk": 257, "fields": {"name": "radial basis function"}}, {"model": "ver0.keyword", "pk": 258, "fields": {"name": "turn-taking"}}, {"model": "ver0.keyword", "pk": 259, "fields": {"name": "imputation"}}, {"model": "ver0.keyword", "pk": 260, "fields": {"name": "AUC"}}, {"model": "ver0.keyword", "pk": 261, "fields": {"name": "deep neural networks"}}, {"model": "ver0.keyword", "pk": 262, "fields": {"name": "exponential smoothing"}}, {"model": "ver0.keyword", "pk": 263, "fields": {"name": "signal"}}, {"model": "ver0.keyword", "pk": 264, "fields": {"name": "speech technology"}}, {"model": "ver0.keyword", "pk": 265, "fields": {"name": "social signals"}}, {"model": "ver0.keyword", "pk": 266, "fields": {"name": "adaboostmh"}}, {"model": "ver0.keyword", "pk": 267, "fields": {"name": "technology"}}, {"model": "ver0.keyword", "pk": 268, "fields": {"name": "perceptual restoration"}}, {"model": "ver0.keyword", "pk": 269, "fields": {"name": "speech perception"}}, {"model": "ver0.keyword", "pk": 270, "fields": {"name": "phonemic restoration"}}, {"model": "ver0.keyword", "pk": 271, "fields": {"name": "restoration"}}, {"model": "ver0.keyword", "pk": 272, "fields": {"name": "second language listening"}}, {"model": "ver0.keyword", "pk": 273, "fields": {"name": "RES"}}, {"model": "ver0.keyword", "pk": 274, "fields": {"name": "automatic estimation"}}, {"model": "ver0.keyword", "pk": 275, "fields": {"name": "web service"}}, {"model": "ver0.keyword", "pk": 276, "fields": {"name": "web interface"}}, {"model": "ver0.keyword", "pk": 277, "fields": {"name": "BAS"}}, {"model": "ver0.keyword", "pk": 278, "fields": {"name": "MAUS"}}, {"model": "ver0.keyword", "pk": 279, "fields": {"name": "text-to-phoneme"}}, {"model": "ver0.keyword", "pk": 280, "fields": {"name": "REST"}}, {"model": "ver0.keyword", "pk": 281, "fields": {"name": "automatic segmentation"}}, {"model": "ver0.keyword", "pk": 282, "fields": {"name": "EST"}}, {"model": "ver0.keyword", "pk": 283, "fields": {"name": "restful web service"}}, {"model": "ver0.keyword", "pk": 284, "fields": {"name": "syllabification"}}, {"model": "ver0.keyword", "pk": 285, "fields": {"name": "motivation"}}, {"model": "ver0.keyword", "pk": 286, "fields": {"name": "reliability"}}, {"model": "ver0.keyword", "pk": 287, "fields": {"name": "assessment"}}, {"model": "ver0.keyword", "pk": 288, "fields": {"name": "speech quality assessment"}}, {"model": "ver0.keyword", "pk": 289, "fields": {"name": "multitask learning"}}, {"model": "ver0.keyword", "pk": 290, "fields": {"name": "WERR"}}, {"model": "ver0.keyword", "pk": 291, "fields": {"name": "CD-DNN-HMM"}}, {"model": "ver0.keyword", "pk": 292, "fields": {"name": "adaptation"}}, {"model": "ver0.keyword", "pk": 293, "fields": {"name": "MTL"}}, {"model": "ver0.keyword", "pk": 294, "fields": {"name": "WSJ"}}, {"model": "ver0.keyword", "pk": 295, "fields": {"name": "DNN"}}, {"model": "ver0.keyword", "pk": 296, "fields": {"name": "ZTW"}}, {"model": "ver0.keyword", "pk": 297, "fields": {"name": "pitch regression"}}, {"model": "ver0.keyword", "pk": 298, "fields": {"name": "zero time windowing"}}, {"model": "ver0.keyword", "pk": 299, "fields": {"name": "numerator of group delay function"}}, {"model": "ver0.keyword", "pk": 300, "fields": {"name": "time windowe"}}, {"model": "ver0.keyword", "pk": 301, "fields": {"name": "group delay function"}}, {"model": "ver0.keyword", "pk": 302, "fields": {"name": "pitch"}}, {"model": "ver0.keyword", "pk": 303, "fields": {"name": "pause"}}, {"model": "ver0.keyword", "pk": 304, "fields": {"name": "prosodic phrasing"}}, {"model": "ver0.keyword", "pk": 305, "fields": {"name": "interlanguage"}}, {"model": "ver0.keyword", "pk": 306, "fields": {"name": "swedish"}}, {"model": "ver0.keyword", "pk": 307, "fields": {"name": "japanese"}}, {"model": "ver0.keyword", "pk": 308, "fields": {"name": "IARPA"}}, {"model": "ver0.keyword", "pk": 309, "fields": {"name": "ARPA"}}, {"model": "ver0.keyword", "pk": 310, "fields": {"name": "RPA"}}, {"model": "ver0.keyword", "pk": 311, "fields": {"name": "RNN"}}, {"model": "ver0.keyword", "pk": 312, "fields": {"name": "multitask training"}}, {"model": "ver0.keyword", "pk": 313, "fields": {"name": "biofeedback"}}, {"model": "ver0.keyword", "pk": 314, "fields": {"name": "tongue"}}, {"model": "ver0.keyword", "pk": 315, "fields": {"name": "segmentation"}}, {"model": "ver0.keyword", "pk": 316, "fields": {"name": "speech therapy"}}, {"model": "ver0.keyword", "pk": 317, "fields": {"name": "ANN"}}, {"model": "ver0.keyword", "pk": 318, "fields": {"name": "ultrasound imaging"}}, {"model": "ver0.keyword", "pk": 319, "fields": {"name": "parameter"}}, {"model": "ver0.keyword", "pk": 320, "fields": {"name": "generalized variable parameter hmm"}}, {"model": "ver0.keyword", "pk": 321, "fields": {"name": "distance feature"}}, {"model": "ver0.keyword", "pk": 322, "fields": {"name": "bottleneck features"}}, {"model": "ver0.keyword", "pk": 323, "fields": {"name": "GVP"}}, {"model": "ver0.keyword", "pk": 324, "fields": {"name": "voice quality"}}, {"model": "ver0.keyword", "pk": 325, "fields": {"name": "intraspeaker variability"}}, {"model": "ver0.keyword", "pk": 326, "fields": {"name": "quality"}}, {"model": "ver0.keyword", "pk": 327, "fields": {"name": "incremental processing"}}, {"model": "ver0.keyword", "pk": 328, "fields": {"name": "speech synthesis"}}, {"model": "ver0.keyword", "pk": 329, "fields": {"name": "effect"}}, {"model": "ver0.keyword", "pk": 330, "fields": {"name": "lombard effect"}}, {"model": "ver0.keyword", "pk": 331, "fields": {"name": "interactive systems"}}, {"model": "ver0.keyword", "pk": 332, "fields": {"name": "dialog system"}}, {"model": "ver0.keyword", "pk": 333, "fields": {"name": "aphasia"}}, {"model": "ver0.keyword", "pk": 334, "fields": {"name": "domain transfer"}}, {"model": "ver0.keyword", "pk": 335, "fields": {"name": "aphasiabank"}}, {"model": "ver0.keyword", "pk": 336, "fields": {"name": "acoustic modeling"}}, {"model": "ver0.keyword", "pk": 337, "fields": {"name": "acoustic classification"}}, {"model": "ver0.keyword", "pk": 338, "fields": {"name": "out-of-domain adaptation"}}, {"model": "ver0.keyword", "pk": 339, "fields": {"name": "law"}}, {"model": "ver0.keyword", "pk": 340, "fields": {"name": "USC"}}, {"model": "ver0.keyword", "pk": 341, "fields": {"name": "real-time mri"}}, {"model": "ver0.keyword", "pk": 342, "fields": {"name": "articulatory difficulty"}}, {"model": "ver0.keyword", "pk": 343, "fields": {"name": "fitts\u2019 law"}}, {"model": "ver0.keyword", "pk": 344, "fields": {"name": "i-vectors"}}, {"model": "ver0.keyword", "pk": 345, "fields": {"name": "partition"}}, {"model": "ver0.keyword", "pk": 346, "fields": {"name": "SUV"}}, {"model": "ver0.keyword", "pk": 347, "fields": {"name": "LDA"}}, {"model": "ver0.keyword", "pk": 348, "fields": {"name": "GPLDA"}}, {"model": "ver0.keyword", "pk": 349, "fields": {"name": "PLDA"}}, {"model": "ver0.keyword", "pk": 350, "fields": {"name": "utterance partitioning"}}, {"model": "ver0.keyword", "pk": 351, "fields": {"name": "EER"}}, {"model": "ver0.keyword", "pk": 352, "fields": {"name": "plda"}}, {"model": "ver0.keyword", "pk": 353, "fields": {"name": "speech analysis"}}, {"model": "ver0.keyword", "pk": 354, "fields": {"name": "SWIPE"}}, {"model": "ver0.keyword", "pk": 355, "fields": {"name": "speech speech"}}, {"model": "ver0.keyword", "pk": 356, "fields": {"name": "speech processing"}}, {"model": "ver0.keyword", "pk": 357, "fields": {"name": "fundamental frequency (f0)"}}, {"model": "ver0.keyword", "pk": 358, "fields": {"name": "fundamental"}}, {"model": "ver0.keyword", "pk": 359, "fields": {"name": "YIN"}}, {"model": "ver0.keyword", "pk": 360, "fields": {"name": "DIO"}}, {"model": "ver0.keyword", "pk": 361, "fields": {"name": "RMA"}}, {"model": "ver0.keyword", "pk": 362, "fields": {"name": "magnetic resonance imaging"}}, {"model": "ver0.keyword", "pk": 363, "fields": {"name": "word selection"}}, {"model": "ver0.keyword", "pk": 364, "fields": {"name": "text-to-speech synthesis"}}, {"model": "ver0.keyword", "pk": 365, "fields": {"name": "LSTM"}}, {"model": "ver0.keyword", "pk": 366, "fields": {"name": "unit-selection"}}, {"model": "ver0.keyword", "pk": 367, "fields": {"name": "SDR"}}, {"model": "ver0.keyword", "pk": 368, "fields": {"name": "query model"}}, {"model": "ver0.keyword", "pk": 369, "fields": {"name": "pseudo relevance feedback"}}, {"model": "ver0.keyword", "pk": 370, "fields": {"name": "significant words"}}, {"model": "ver0.keyword", "pk": 371, "fields": {"name": "word"}}, {"model": "ver0.keyword", "pk": 372, "fields": {"name": "textural features"}}, {"model": "ver0.keyword", "pk": 373, "fields": {"name": "voice source features"}}, {"model": "ver0.keyword", "pk": 374, "fields": {"name": "cross-modal sentiment correlation"}}, {"model": "ver0.keyword", "pk": 375, "fields": {"name": "phonation difference"}}, {"model": "ver0.keyword", "pk": 376, "fields": {"name": "phonation differences"}}, {"model": "ver0.keyword", "pk": 377, "fields": {"name": "mammalian vocalisation"}}, {"model": "ver0.keyword", "pk": 378, "fields": {"name": "INT"}}, {"model": "ver0.keyword", "pk": 379, "fields": {"name": "SPE"}}, {"model": "ver0.keyword", "pk": 380, "fields": {"name": "vocal synthesis"}}, {"model": "ver0.keyword", "pk": 381, "fields": {"name": "biomimetic robot"}}, {"model": "ver0.keyword", "pk": 382, "fields": {"name": "TER"}}, {"model": "ver0.keyword", "pk": 383, "fields": {"name": "INTERSPEECH"}}, {"model": "ver0.keyword", "pk": 384, "fields": {"name": "miro"}}, {"model": "ver0.keyword", "pk": 385, "fields": {"name": "synthesis"}}, {"model": "ver0.keyword", "pk": 386, "fields": {"name": "neural network hardware"}}, {"model": "ver0.keyword", "pk": 387, "fields": {"name": "SRAM"}}, {"model": "ver0.keyword", "pk": 388, "fields": {"name": "language model"}}, {"model": "ver0.keyword", "pk": 389, "fields": {"name": "4MB"}}, {"model": "ver0.keyword", "pk": 390, "fields": {"name": "hardware"}}, {"model": "ver0.keyword", "pk": 391, "fields": {"name": "natural language understanding"}}, {"model": "ver0.keyword", "pk": 392, "fields": {"name": "DSP"}}, {"model": "ver0.keyword", "pk": 393, "fields": {"name": "BAB"}}, {"model": "ver0.keyword", "pk": 394, "fields": {"name": "TWV"}}, {"model": "ver0.keyword", "pk": 395, "fields": {"name": "KWS"}}, {"model": "ver0.keyword", "pk": 396, "fields": {"name": "BABEL"}}, {"model": "ver0.keyword", "pk": 397, "fields": {"name": "keyword search"}}, {"model": "ver0.keyword", "pk": 398, "fields": {"name": "ATWV"}}, {"model": "ver0.keyword", "pk": 399, "fields": {"name": "iarpa babel"}}, {"model": "ver0.keyword", "pk": 400, "fields": {"name": "openkws"}}, {"model": "ver0.keyword", "pk": 401, "fields": {"name": "denoising autoencoder"}}, {"model": "ver0.keyword", "pk": 402, "fields": {"name": "EDA"}}, {"model": "ver0.keyword", "pk": 403, "fields": {"name": "autoencoder"}}, {"model": "ver0.keyword", "pk": 404, "fields": {"name": "AED"}}, {"model": "ver0.keyword", "pk": 405, "fields": {"name": "AEDA"}}, {"model": "ver0.keyword", "pk": 406, "fields": {"name": "denoise autoencoder"}}, {"model": "ver0.keyword", "pk": 407, "fields": {"name": "unsupervised domain adaptation"}}, {"model": "ver0.keyword", "pk": 408, "fields": {"name": "domain mismatch"}}, {"model": "ver0.keyword", "pk": 409, "fields": {"name": "lecture data"}}, {"model": "ver0.keyword", "pk": 410, "fields": {"name": "dtw"}}, {"model": "ver0.keyword", "pk": 411, "fields": {"name": "slide-speech alignment"}}, {"model": "ver0.keyword", "pk": 412, "fields": {"name": "DTW"}}, {"model": "ver0.keyword", "pk": 413, "fields": {"name": "discourse analysis"}}, {"model": "ver0.keyword", "pk": 414, "fields": {"name": "conversational speech"}}, {"model": "ver0.keyword", "pk": 415, "fields": {"name": "prosody"}}, {"model": "ver0.keyword", "pk": 416, "fields": {"name": "analysis"}}, {"model": "ver0.keyword", "pk": 417, "fields": {"name": "NCE"}}, {"model": "ver0.keyword", "pk": 418, "fields": {"name": "100K"}}, {"model": "ver0.keyword", "pk": 419, "fields": {"name": "KLD"}}, {"model": "ver0.keyword", "pk": 420, "fields": {"name": "ESL"}}, {"model": "ver0.keyword", "pk": 421, "fields": {"name": "pronunciation quality evaluation"}}, {"model": "ver0.keyword", "pk": 422, "fields": {"name": "evaluation"}}, {"model": "ver0.keyword", "pk": 423, "fields": {"name": "GOP"}}, {"model": "ver0.keyword", "pk": 424, "fields": {"name": "deep nerual network"}}, {"model": "ver0.keyword", "pk": 425, "fields": {"name": "computer-aided language learning"}}, {"model": "ver0.keyword", "pk": 426, "fields": {"name": "source separation"}}, {"model": "ver0.keyword", "pk": 427, "fields": {"name": "source"}}, {"model": "ver0.keyword", "pk": 428, "fields": {"name": "speaker extraction"}}, {"model": "ver0.keyword", "pk": 429, "fields": {"name": "PESQ"}}, {"model": "ver0.keyword", "pk": 430, "fields": {"name": "end-to-end asr"}}, {"model": "ver0.keyword", "pk": 431, "fields": {"name": "overlapped speech"}}, {"model": "ver0.keyword", "pk": 432, "fields": {"name": "end end asr"}}, {"model": "ver0.keyword", "pk": 433, "fields": {"name": "pitch range"}}, {"model": "ver0.keyword", "pk": 434, "fields": {"name": "views"}}, {"model": "ver0.keyword", "pk": 435, "fields": {"name": "subscribers"}}, {"model": "ver0.keyword", "pk": 436, "fields": {"name": "intensity variation"}}, {"model": "ver0.keyword", "pk": 437, "fields": {"name": "charisma"}}, {"model": "ver0.keyword", "pk": 438, "fields": {"name": "youtube"}}, {"model": "ver0.keyword", "pk": 439, "fields": {"name": "subscriber"}}, {"model": "ver0.keyword", "pk": 440, "fields": {"name": "likes"}}, {"model": "ver0.keyword", "pk": 441, "fields": {"name": "articulation"}}, {"model": "ver0.keyword", "pk": 442, "fields": {"name": "fricative"}}, {"model": "ver0.keyword", "pk": 443, "fields": {"name": "secondary palatalization"}}, {"model": "ver0.keyword", "pk": 444, "fields": {"name": "romanian"}}, {"model": "ver0.keyword", "pk": 445, "fields": {"name": "fricatives"}}, {"model": "ver0.keyword", "pk": 446, "fields": {"name": "convolutional neural networks"}}, {"model": "ver0.keyword", "pk": 447, "fields": {"name": "raw-waveform modelling"}}, {"model": "ver0.keyword", "pk": 448, "fields": {"name": "computational paralinguistics"}}, {"model": "ver0.keyword", "pk": 449, "fields": {"name": "source-filter decomposition"}}, {"model": "ver0.keyword", "pk": 450, "fields": {"name": "raw waveform modelling"}}, {"model": "ver0.keyword", "pk": 451, "fields": {"name": "articulatory modelling"}}, {"model": "ver0.keyword", "pk": 452, "fields": {"name": "affective computing"}}, {"model": "ver0.keyword", "pk": 453, "fields": {"name": "health application"}}, {"model": "ver0.keyword", "pk": 454, "fields": {"name": "NLP"}}, {"model": "ver0.keyword", "pk": 455, "fields": {"name": "health applications"}}, {"model": "ver0.keyword", "pk": 456, "fields": {"name": "paralinguistics"}}, {"model": "ver0.keyword", "pk": 457, "fields": {"name": "learning"}}, {"model": "ver0.keyword", "pk": 458, "fields": {"name": "depression"}}, {"model": "ver0.keyword", "pk": 459, "fields": {"name": "deep learning"}}, {"model": "ver0.keyword", "pk": 460, "fields": {"name": "lexical stress and pre-pausal lengthening"}}, {"model": "ver0.keyword", "pk": 461, "fields": {"name": "lexical stress pre - pausal lengthening"}}, {"model": "ver0.keyword", "pk": 462, "fields": {"name": "duration modeling"}}, {"model": "ver0.keyword", "pk": 463, "fields": {"name": "phonetic features"}}, {"model": "ver0.keyword", "pk": 464, "fields": {"name": "parkinson\u2019s disease"}}, {"model": "ver0.keyword", "pk": 465, "fields": {"name": "dysarthria"}}, {"model": "ver0.keyword", "pk": 466, "fields": {"name": "word error rate"}}, {"model": "ver0.keyword", "pk": 467, "fields": {"name": "variational autoencoder"}}, {"model": "ver0.keyword", "pk": 468, "fields": {"name": "CMN2"}}, {"model": "ver0.keyword", "pk": 469, "fields": {"name": "DAN"}}, {"model": "ver0.keyword", "pk": 470, "fields": {"name": "VAE"}}, {"model": "ver0.keyword", "pk": 471, "fields": {"name": "SRE18"}}, {"model": "ver0.keyword", "pk": 472, "fields": {"name": "domain adaptation"}}, {"model": "ver0.keyword", "pk": 473, "fields": {"name": "SRE16"}}, {"model": "ver0.keyword", "pk": 474, "fields": {"name": "CMN"}}, {"model": "ver0.keyword", "pk": 475, "fields": {"name": "VDANN"}}, {"model": "ver0.keyword", "pk": 476, "fields": {"name": "DANN"}}, {"model": "ver0.keyword", "pk": 477, "fields": {"name": "domain adversarial training"}}, {"model": "ver0.keyword", "pk": 478, "fields": {"name": "lstm neural network"}}, {"model": "ver0.keyword", "pk": 479, "fields": {"name": "continuous mandarin speech"}}, {"model": "ver0.keyword", "pk": 480, "fields": {"name": "tone modeling and recognition"}}, {"model": "ver0.keyword", "pk": 481, "fields": {"name": "target approximation model"}}, {"model": "ver0.keyword", "pk": 482, "fields": {"name": "incremental speech synthesis"}}, {"model": "ver0.keyword", "pk": 483, "fields": {"name": "representation learning"}}, {"model": "ver0.keyword", "pk": 484, "fields": {"name": "representation"}}, {"model": "ver0.keyword", "pk": 485, "fields": {"name": "MUSHRA"}}, {"model": "ver0.keyword", "pk": 486, "fields": {"name": "SHR"}}, {"model": "ver0.keyword", "pk": 487, "fields": {"name": "acoustic modelling"}}, {"model": "ver0.keyword", "pk": 488, "fields": {"name": "training dynamics"}}, {"model": "ver0.keyword", "pk": 489, "fields": {"name": "MFC"}}, {"model": "ver0.keyword", "pk": 490, "fields": {"name": "average frequency response"}}, {"model": "ver0.keyword", "pk": 491, "fields": {"name": "MFCC"}}, {"model": "ver0.keyword", "pk": 492, "fields": {"name": "raw waveform"}}, {"model": "ver0.keyword", "pk": 493, "fields": {"name": "multi - modal"}}, {"model": "ver0.keyword", "pk": 494, "fields": {"name": "ASV"}}, {"model": "ver0.keyword", "pk": 495, "fields": {"name": "spoofing; sub-band countermeasures; presentation attack detection; asvspoof; speaker verification"}}, {"model": "ver0.keyword", "pk": 496, "fields": {"name": "speech evaluation"}}, {"model": "ver0.keyword", "pk": 497, "fields": {"name": "speech feature extraction"}}, {"model": "ver0.keyword", "pk": 498, "fields": {"name": "FVDM"}}, {"model": "ver0.keyword", "pk": 499, "fields": {"name": "vowel distortion"}}, {"model": "ver0.keyword", "pk": 500, "fields": {"name": "disordered speech"}}, {"model": "ver0.keyword", "pk": 501, "fields": {"name": "huntington disease"}}, {"model": "ver0.keyword", "pk": 502, "fields": {"name": "neural machine translation"}}, {"model": "ver0.keyword", "pk": 503, "fields": {"name": "machine translation"}}, {"model": "ver0.keyword", "pk": 504, "fields": {"name": "AVS"}}, {"model": "ver0.keyword", "pk": 505, "fields": {"name": "multimodal learning"}}, {"model": "ver0.keyword", "pk": 506, "fields": {"name": "multi-task learning"}}, {"model": "ver0.keyword", "pk": 507, "fields": {"name": "TMT"}}, {"model": "ver0.keyword", "pk": 508, "fields": {"name": "AVSD"}}, {"model": "ver0.keyword", "pk": 509, "fields": {"name": "audio-visual scene-aware dialog"}}, {"model": "ver0.keyword", "pk": 510, "fields": {"name": "MTN"}}, {"model": "ver0.keyword", "pk": 511, "fields": {"name": "NMT"}}, {"model": "ver0.keyword", "pk": 512, "fields": {"name": "code switching"}}, {"model": "ver0.keyword", "pk": 513, "fields": {"name": "E2E"}}, {"model": "ver0.keyword", "pk": 514, "fields": {"name": "multilingual"}}, {"model": "ver0.keyword", "pk": 515, "fields": {"name": "code-switching"}}, {"model": "ver0.keyword", "pk": 516, "fields": {"name": "multi-dialectal"}}, {"model": "ver0.keyword", "pk": 517, "fields": {"name": "MSA"}}, {"model": "ver0.keyword", "pk": 518, "fields": {"name": "conformer"}}, {"model": "ver0.keyword", "pk": 519, "fields": {"name": "end end"}}, {"model": "ver0.keyword", "pk": 520, "fields": {"name": "on-device"}}, {"model": "ver0.keyword", "pk": 521, "fields": {"name": "limited memory"}}, {"model": "ver0.keyword", "pk": 522, "fields": {"name": "device"}}, {"model": "ver0.keyword", "pk": 523, "fields": {"name": "end-to-end"}}, {"model": "ver0.keyword", "pk": 524, "fields": {"name": "image based jaw measurement"}}, {"model": "ver0.keyword", "pk": 525, "fields": {"name": "jaw movement simulation"}}, {"model": "ver0.keyword", "pk": 526, "fields": {"name": "articulatory simulation"}}, {"model": "ver0.keyword", "pk": 527, "fields": {"name": "jaw kinematics"}}, {"model": "ver0.keyword", "pk": 528, "fields": {"name": "simulation"}}, {"model": "ver0.keyword", "pk": 529, "fields": {"name": "nasal"}}, {"model": "ver0.keyword", "pk": 530, "fields": {"name": "velum"}}, {"model": "ver0.keyword", "pk": 531, "fields": {"name": "articulatory phonology"}}, {"model": "ver0.keyword", "pk": 532, "fields": {"name": "speech imaging"}}, {"model": "ver0.keyword", "pk": 533, "fields": {"name": "phonology"}}, {"model": "ver0.keyword", "pk": 534, "fields": {"name": "nasal consonants"}}, {"model": "ver0.keyword", "pk": 535, "fields": {"name": "nasals"}}, {"model": "ver0.keyword", "pk": 536, "fields": {"name": "dialogue learning"}}, {"model": "ver0.keyword", "pk": 537, "fields": {"name": "reinforcement learning"}}, {"model": "ver0.keyword", "pk": 538, "fields": {"name": "emotional text tospeech synthesis"}}, {"model": "ver0.keyword", "pk": 539, "fields": {"name": "speech emotion recognition"}}, {"model": "ver0.keyword", "pk": 540, "fields": {"name": "emotional text-tospeech synthesis"}}, {"model": "ver0.keyword", "pk": 541, "fields": {"name": "ITU"}}, {"model": "ver0.keyword", "pk": 542, "fields": {"name": "POLQA"}}, {"model": "ver0.keyword", "pk": 543, "fields": {"name": "MOS"}}, {"model": "ver0.keyword", "pk": 544, "fields": {"name": "VCTK"}}, {"model": "ver0.keyword", "pk": 545, "fields": {"name": "transfer learning"}}, {"model": "ver0.keyword", "pk": 546, "fields": {"name": "speech rate"}}, {"model": "ver0.keyword", "pk": 547, "fields": {"name": "obstruents"}}, {"model": "ver0.keyword", "pk": 548, "fields": {"name": "french german interference"}}, {"model": "ver0.keyword", "pk": 549, "fields": {"name": "french/german interferences"}}, {"model": "ver0.keyword", "pk": 550, "fields": {"name": "L2"}}, {"model": "ver0.keyword", "pk": 551, "fields": {"name": "voicing assimilation"}}, {"model": "ver0.keyword", "pk": 552, "fields": {"name": "language identification"}}, {"model": "ver0.keyword", "pk": 553, "fields": {"name": "TCS"}}, {"model": "ver0.keyword", "pk": 554, "fields": {"name": "end-to-end neural diarization"}}, {"model": "ver0.keyword", "pk": 555, "fields": {"name": "SEAME"}}, {"model": "ver0.keyword", "pk": 556, "fields": {"name": "CSM"}}, {"model": "ver0.keyword", "pk": 557, "fields": {"name": "STC"}}, {"model": "ver0.keyword", "pk": 558, "fields": {"name": "temporal attention"}}, {"model": "ver0.keyword", "pk": 559, "fields": {"name": "end end neural diarization"}}, {"model": "ver0.keyword", "pk": 560, "fields": {"name": "BLSTM"}}, {"model": "ver0.keyword", "pk": 561, "fields": {"name": "EAM"}}, {"model": "ver0.keyword", "pk": 562, "fields": {"name": "AME"}}, {"model": "ver0.keyword", "pk": 563, "fields": {"name": "self-attention"}}, {"model": "ver0.keyword", "pk": 564, "fields": {"name": "language diarization"}}, {"model": "ver0.keyword", "pk": 565, "fields": {"name": "voice source"}}, {"model": "ver0.keyword", "pk": 566, "fields": {"name": "laplace transform"}}, {"model": "ver0.keyword", "pk": 567, "fields": {"name": "glottal airflow"}}, {"model": "ver0.keyword", "pk": 568, "fields": {"name": "voice"}}, {"model": "ver0.keyword", "pk": 569, "fields": {"name": "frequency domain lf model"}}, {"model": "ver0.keyword", "pk": 570, "fields": {"name": "aliasing"}}, {"model": "ver0.keyword", "pk": 571, "fields": {"name": "aliase"}}, {"model": "ver0.keyword", "pk": 572, "fields": {"name": "phasor"}}]