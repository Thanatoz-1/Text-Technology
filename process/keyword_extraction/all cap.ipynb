{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4A5n6hFPpYv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "xmlpath = '/content/drive/MyDrive/2021/stuttgart/Text Tech Team/resources/interspeech/all_formatted.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiS1rHbOQv-l"
   },
   "outputs": [],
   "source": [
    "# load format.xml to python object\n",
    "import xml.etree.ElementTree as ET\n",
    "class PaperLoader:\n",
    "    def __init__(self, xmlpath):\n",
    "        tree = ET.parse(xmlpath)\n",
    "        self.root = tree.getroot()\n",
    "        confs = self.root.findall('.//conference')\n",
    "        self.abst = []\n",
    "        self.keys = []\n",
    "        for conf in confs:\n",
    "            for paper in conf.findall('.//paper'):\n",
    "                abst = paper.find('abstract').text \n",
    "                key_root = paper.find('.keywords')\n",
    "                keys = []\n",
    "                for key in key_root.findall('.//keyword'):\n",
    "                    keys.append(key.text)\n",
    "                self.abst.append(abst)\n",
    "                self.keys.append(keys)\n",
    "papers = PaperLoader(xmlpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNFiD6S8RUfI",
    "outputId": "69151ceb-24a8-422e-ba60-3adbb93b3fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7928\n"
     ]
    }
   ],
   "source": [
    "print(len(papers.abst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16x5jRaZTAh7"
   },
   "outputs": [],
   "source": [
    "# abst to words\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_short\n",
    "def normalization(sentence):\n",
    "    PUNC_FILTERS = [lambda x: x, strip_tags, strip_punctuation, strip_short]\n",
    "    all_words = []\n",
    "    for s in sentence:\n",
    "        res = preprocess_string(s, PUNC_FILTERS)\n",
    "        all_words += res\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CosPcN4LTl2d",
    "outputId": "0d446b5b-c111-448e-bd97-d43946789667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971081\n"
     ]
    }
   ],
   "source": [
    "all_words = normalization(papers.abst)\n",
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaacGX2KWFj6"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def extract_captials(words):\n",
    "    cwords = Counter()\n",
    "    for w in words:\n",
    "        if w.isupper():\n",
    "            cwords[w] += 1      \n",
    "    return cwords\n",
    "cwords = extract_captials(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ml7M0F2TFuE8"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_cap.dict', 'wb') as f:\n",
    "    pickle.dump(cwords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cOzRXHIa-tb",
    "outputId": "3ba7a516-932f-4f3b-82f1-1ee487b44e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ASR', 1923), ('DNN', 1361), ('HMM', 746), ('GMM', 586), ('WER', 542), ('LSTM', 506), ('TTS', 472), ('CNN', 416), ('RNN', 375), ('NIST', 342), ('MFCC', 320), ('PLDA', 273), ('EER', 265), ('SNR', 260), ('CTC', 239), ('SVM', 220), ('VAD', 212), ('TIMIT', 209), ('NMF', 199), ('BLSTM', 178), ('SRE', 163), ('OOV', 158), ('UBM', 156), ('SLU', 144), ('STD', 139), ('LVCSR', 138), ('KWS', 135), ('TDNN', 133), ('ASV', 120), ('LDA', 118), ('E2E', 118), ('MRI', 117), ('CRF', 106), ('MLP', 99), ('EMA', 93), ('GAN', 91), ('DTW', 89), ('SER', 89), ('LID', 86), ('G2P', 83), ('MAP', 82), ('SAD', 79), ('ALS', 78), ('INTERSPEECH', 77), ('VOT', 76), ('AMI', 73), ('PESQ', 73), ('MTL', 73), ('VAE', 72), ('MMI', 70), ('RNNLM', 68), ('MOS', 67), ('ASD', 66), ('IEMOCAP', 65), ('EEG', 63), ('MMSE', 62), ('STFT', 58), ('WFST', 56), ('PCA', 55), ('VTLN', 54), ('DOA', 53), ('UAR', 53), ('EMG', 52), ('GPU', 52), ('MLLR', 49), ('SDR', 49), ('EGG', 49), ('GCI', 49), ('LRE', 48), ('GRU', 48), ('NLP', 47), ('ABX', 47), ('CER', 47), ('IARPA', 47), ('WSJ', 46), ('DAE', 46), ('ANN', 45), ('STOI', 45), ('SAT', 44), ('MSA', 44), ('BERT', 43), ('IBM', 42), ('AED', 42), ('SDS', 41), ('BIC', 41), ('JFA', 41), ('TED', 41), ('AAI', 41), ('DER', 40), ('POS', 40), ('CPU', 40), ('SPSS', 39), ('WPE', 39), ('DBN', 38), ('AUC', 38), ('CMLLR', 37), ('LSF', 37), ('WSJ0', 36), ('BSS', 36), ('MCI', 36)]\n"
     ]
    }
   ],
   "source": [
    "top50 = cwords.most_common(100)\n",
    "print(top50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "keywords extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
