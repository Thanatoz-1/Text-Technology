{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SszW2c_88gen"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api\n",
        "\n",
        "import spacy\n",
        "import xml.etree.ElementTree as ET "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xmlpath = '/content/drive/MyDrive/2021/stuttgart/Text Tech Team/resources/interspeech/all_formatted.xml'\n",
        "tree = ET.parse(xmlpath)\n",
        "root = tree.getroot() \n",
        "# https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html\n",
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "id": "XgLphfmqhOde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e77026-9f35-417c-8832-6e07958418cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_terms = []\n",
        "for conf in root:\n",
        "    meta = conf[0]\n",
        "    papers = conf[1]\n",
        "    \n",
        "    for paper in papers:\n",
        "        for key in paper[4]:\n",
        "            key = key.text\n",
        "            clean_key = gensim.utils.simple_preprocess(key, deacc=True)\n",
        "            index_terms.append(clean_key)"
      ],
      "metadata": {
        "id": "EVas-32ZhXIJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "def lemmatisation(words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    ret = []\n",
        "    for sent in words:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        ret.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
        "    return ret\n",
        "\n",
        "# Only use open class data\n",
        "lemmas = lemmatisation(index_terms)\n",
        "data_uniq = list(set(lemmas))\n",
        "print(len(lemmas), len(data_uniq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_KjTLNjyNwX",
        "outputId": "64d2f227-820b-428a-c032-7c4093c0f915"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32126 8367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_index_term(terms, model):\n",
        "    fail = []\n",
        "    success = []\n",
        "    label = []\n",
        "    for keys in terms:\n",
        "        keys = keys.strip().split()\n",
        "        status, vec = embed_one(keys, model)\n",
        "        if status:\n",
        "            success.append(vec)\n",
        "            label.append(' '.join(keys))\n",
        "        else:\n",
        "            fail.append(vec)\n",
        "    return fail, success, label\n",
        "\n",
        "def embed_one(keys, model):\n",
        "    all_in = True\n",
        "    for key in keys:\n",
        "        if key not in model.vocab:\n",
        "            all_in = False\n",
        "            break\n",
        "    \n",
        "    if not all_in:\n",
        "        return False, keys\n",
        "    ret = np.zeros((50), dtype=float)\n",
        "    for key in keys:\n",
        "        ret += np.array(model[key], dtype=float)\n",
        "    return True, ret\n",
        "fail, success, label = embed_index_term(data_uniq, model)"
      ],
      "metadata": {
        "id": "67QzXKYNl6ly"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cluster \n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "kmeans = KMeans(n_clusters=100, init='k-means++')\n",
        "data_mat = np.array(success)\n",
        "kmeans.fit(data_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP_DPkcLpZzM",
        "outputId": "05635c5f-c209-4c1a-f9a5-484f31b00200"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "cluster = collections.defaultdict(list)\n",
        "for idx, c in enumerate(kmeans.labels_):\n",
        "    cluster[c].append(label[idx])"
      ],
      "metadata": {
        "id": "KUcIg4_hp2ys"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in cluster[0]:\n",
        "    print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BATGKPq1q4lQ",
        "outputId": "5ba25f73-16a6-4671-8122-81fd4307bc79"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polyphonic sound event detection se\n",
            "cross multilingual acoustic lexical modeling preprocessing\n",
            "acoustic event classification detection\n",
            "animated vocal model\n",
            "multilingual acoustic model\n",
            "acoustic feature tag perceive emphasis\n",
            "acoustic event detection\n",
            "acoustic unit discovery\n",
            "low resource acoustic modeling\n",
            "acoustic scene classification\n",
            "acoustic concept index\n",
            "acoustic prominence modeling\n",
            "ensemble acoustic model\n",
            "acoustic scene analysis\n",
            "rich acoustic feature\n",
            "automate acoustic analysis\n",
            "acoustic model\n",
            "multi dialect acoustic modeling\n",
            "unsupervised acoustic unit mining\n",
            "acoustic adaptation hypothesis\n",
            "acoustic voice parameter\n",
            "datum drive acoustic modeling\n",
            "multilingual acoustic modeling\n",
            "music genre classification\n",
            "acoustic trading relation\n",
            "acoustic model adaptation\n",
            "multilingual acoustic modelling\n",
            "acoustic feature\n",
            "description acoustic unit\n",
            "russian acoustic feature\n",
            "acoustic feature compression\n",
            "visual feature extraction\n",
            "acoustic feature selection\n",
            "acoustic methodology\n",
            "acoustic background detection\n",
            "robust acoustic modeling\n",
            "acoustic mapping\n",
            "acoustic event recognition\n",
            "piano performance evaluation\n",
            "acoustic source localization\n",
            "acoustic concept recognition\n",
            "percussion instrument\n",
            "acoustic segment model\n",
            "train acoustic model\n",
            "acoustic event classification\n",
            "acoustic classification\n",
            "weight shift acoustic cue\n",
            "robust acoustic model\n",
            "key acoustic feature\n",
            "acoustic group feature selection\n",
            "independent acoustic modeling\n",
            "acoustic language modeling\n",
            "synthetic feature generation\n",
            "linguistic acoustic feature\n",
            "adaptation acoustic model\n",
            "resource limit acoustic modeling\n",
            "acoustic model selection\n",
            "early experimental phonetic\n",
            "fusion acoustic prosodic feature\n",
            "ensemble regression datum collection scoring\n",
            "acoustic modeling recently\n",
            "ensemble acoustic modeling\n",
            "acoustic word model\n",
            "acoustic textual feature embedding\n",
            "acoustic feedback cancellation\n",
            "acoustic event detection aed\n",
            "voice production exceptional loudness\n",
            "joint acoustic model\n",
            "adaptive acoustic model\n",
            "syllable base acoustic modeling\n",
            "acoustic seed model\n",
            "feature acoustic phonetic feature\n",
            "room acoustic adaptation\n",
            "combine electric acoustic stimulation\n",
            "acoustic model training\n",
            "acoustic feature extraction\n",
            "unsupervised acoustic model\n",
            "acoustic feature learning\n",
            "sound event classification\n",
            "acoustic phonetic description\n",
            "acoustic linguistic emotion recognition\n",
            "acoustic model combination\n",
            "lack acoustic feedback\n",
            "acoustic indoor localization\n",
            "acoustic model cluster\n",
            "speaker room acoustic adaptation\n",
            "acoustic phonetic feature\n",
            "acoustic modeling\n",
            "fine acoustic cue\n",
            "quantitative acoustic analysis\n",
            "context dependent acoustic modelling\n"
          ]
        }
      ]
    }
  ]
}