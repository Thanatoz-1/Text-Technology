{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "72kc41UguOH0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "# Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8JzswHCOwcwN"
   },
   "outputs": [],
   "source": [
    "xmlpath = '/content/drive/MyDrive/2021/stuttgart/Text Tech Team/resources/interspeech/all_formatted.xml'\n",
    "tree = ET.parse(xmlpath)\n",
    "root = tree.getroot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5a6F7aO3xSIk"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for conf in root:\n",
    "    meta = conf[0]\n",
    "    papers = conf[1]\n",
    "    for paper in papers:\n",
    "        corpus.append(paper[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KknoyH_qx_Cf"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  \n",
    "\n",
    "words = list(sent_to_words(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ccDai8JnyLi6"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "def lemmatisation(words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    ret = []\n",
    "    for sent in words:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        ret.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return ret\n",
    "\n",
    "# Only use open class data\n",
    "lemmas = lemmatisation(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uVh7q3uv1Oxp"
   },
   "outputs": [],
   "source": [
    "def lists_to_sents(word_list):\n",
    "    ret = []\n",
    "    for x in word_list:\n",
    "        ret.append(\" \".join(x))\n",
    "    return ret \n",
    "\n",
    "# the original corpus with lowercase and without punctuations\n",
    "naive_corpus = lists_to_sents(words)\n",
    "# form sentences with lemmas \n",
    "lemma_corpus = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AMlsTr991hFX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "def train_one_corpus(corpus, sample_id = 2):\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "    fitted_vectorizer=tfidf_vectorizer.fit(corpus)\n",
    "    tfidf_vectorizer_vectors=fitted_vectorizer.transform(corpus)\n",
    "    sample = tfidf_vectorizer_vectors[sample_id]\n",
    "    df = pd.DataFrame(sample.T.todense(), index=fitted_vectorizer.get_feature_names(), columns=[\"tfidf\"]) \n",
    "    print(naive_corpus[sample_id])\n",
    "    res = df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9MPuLyE1t26",
    "outputId": "44738183-11c4-4992-caa9-e04a711232ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear dynamic models ldms have been shown to be viable alternative to hidden markov models hmms on small vocabulary recognition tasks such as phone classification in this paper we investigate various statistical model combination approaches for hybrid hmm ldm recognizer resulting in phone classification performance that outperforms the best individual classifier further we report on continuous speech recognition experiments on the aurora corpus where the model combination is carried out on wordgraph rescoring while the hybrid system improves the hmm system in the case of monophone hmms the performance of the triphone hmm model could not be improved by monophone ldms asking for the need to introduce context dependency also in the ldm model inventory\n",
      "               tfidf\n",
      "ldm         0.349247\n",
      "ldms        0.337932\n",
      "monophone   0.276649\n",
      "hmm         0.231771\n",
      "hmms        0.215474\n",
      "...              ...\n",
      "fb          0.000000\n",
      "favours     0.000000\n",
      "favoured    0.000000\n",
      "favourably  0.000000\n",
      "ùõøt          0.000000\n",
      "\n",
      "[18779 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_one_corpus(naive_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnADUa4xvpRy",
    "outputId": "8c1cc687-bbad-42cd-95de-7a7a319861cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear dynamic models ldms have been shown to be viable alternative to hidden markov models hmms on small vocabulary recognition tasks such as phone classification in this paper we investigate various statistical model combination approaches for hybrid hmm ldm recognizer resulting in phone classification performance that outperforms the best individual classifier further we report on continuous speech recognition experiments on the aurora corpus where the model combination is carried out on wordgraph rescoring while the hybrid system improves the hmm system in the case of monophone hmms the performance of the triphone hmm model could not be improved by monophone ldms asking for the need to introduce context dependency also in the ldm model inventory\n",
      "              tfidf\n",
      "ldms       0.413690\n",
      "monophone  0.333849\n",
      "hmms       0.270670\n",
      "model      0.252178\n",
      "wordgraph  0.223532\n",
      "...             ...\n",
      "fave       0.000000\n",
      "favor      0.000000\n",
      "favorable  0.000000\n",
      "favorably  0.000000\n",
      "ùõøf         0.000000\n",
      "\n",
      "[12783 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_one_corpus(lemma_corpus)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tfidf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
